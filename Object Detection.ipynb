{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2938,
     "status": "ok",
     "timestamp": 1587377081931,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "LROgLcgNnm3J",
    "outputId": "01cb0d0d-af69-4635-f94c-ff591e1dd15a"
   },
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8332,
     "status": "ok",
     "timestamp": 1587377095230,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "-kC9GGy5pYwC",
    "outputId": "2655675c-db90-49d5-e097-01c45953ab94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/zzh8829/yolov3-tf2.git@master\n",
      "  Cloning https://github.com/zzh8829/yolov3-tf2.git (to revision master) to c:\\users\\dell\\appdata\\local\\temp\\pip-req-build-2trixfz8\n",
      "Requirement already satisfied (use --upgrade to upgrade): yolov3-tf2==0.1 from git+https://github.com/zzh8829/yolov3-tf2.git@master in c:\\users\\dell\\anaconda\\lib\\site-packages\n",
      "Building wheels for collected packages: yolov3-tf2\n",
      "  Building wheel for yolov3-tf2 (setup.py): started\n",
      "  Building wheel for yolov3-tf2 (setup.py): finished with status 'done'\n",
      "  Created wheel for yolov3-tf2: filename=yolov3_tf2-0.1-py3-none-any.whl size=9301 sha256=eba2946353989419cde84be620c18289b331d566196a8059809038387389d976\n",
      "  Stored in directory: C:\\Users\\dell\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-gqiq4_ik\\wheels\\dc\\40\\57\\f6ce9c0aa58da78f10d29a11476132dbf0a616bb92826be28f\n",
      "Successfully built yolov3-tf2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/zzh8829/yolov3-tf2.git 'C:\\Users\\dell\\AppData\\Local\\Temp\\pip-req-build-2trixfz8'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install git+https://github.com/zzh8829/yolov3-tf2.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4853,
     "status": "ok",
     "timestamp": 1587377095232,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "6Jc-plT9qSgj",
    "outputId": "0a74e689-a456-46b8-9e7a-82b7f6ff92ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py\n",
      "\r",
      "8192/1067 [======================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "ROOT = os.path.join(os.getcwd(),'yolo')\n",
    "\n",
    "filename_darknet_weights = tf.keras.utils.get_file(\n",
    "    os.path.join(ROOT,'yolov3.weights'),\n",
    "    origin='https://pjreddie.com/media/files/yolov3.weights')\n",
    "TINY = False\n",
    "\n",
    "filename_convert_script = tf.keras.utils.get_file(\n",
    "    os.path.join(os.getcwd(),'convert.py'),\n",
    "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/convert.py')\n",
    "\n",
    "filename_classes = tf.keras.utils.get_file(\n",
    "    os.path.join(ROOT,'coco.names'),\n",
    "    origin='https://raw.githubusercontent.com/zzh8829/yolov3-tf2/master/data/coco.names')\n",
    "filename_converted_weights = os.path.join(ROOT,'yolov3.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18801,
     "status": "ok",
     "timestamp": 1587377119347,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "tN3rRV-EqajN",
    "outputId": "6977149d-a179-4456-b1b6-a6af90c1cc1a"
   },
   "outputs": [],
   "source": [
    "# copy paste the above code in cmd\n",
    "#python convert.py --weights ./yolo/yolov3.weights --output ./yolo/yolov3.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvjoyMSYvrCu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(filename_convert_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9900,
     "status": "ok",
     "timestamp": 1587377119352,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "H9FxGF2Nv3-w",
    "outputId": "f1618129-ab42-421d-8373-d05447998e49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\dell\\\\anaconda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from yolov3_tf2.models import (YoloV3, YoloV3Tiny)\n",
    "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
    "from yolov3_tf2.utils import draw_outputs\n",
    "import sys\n",
    "from PIL import Image, ImageFile\n",
    "import requests\n",
    "\n",
    "# Flags are used to define several options for YOLO.\n",
    "flags.DEFINE_string('classes', filename_classes, 'path to classes file')\n",
    "flags.DEFINE_string('weights', filename_converted_weights, 'path to weights file')\n",
    "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
    "flags.DEFINE_integer('size', 416, 'resize images to')\n",
    "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
    "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
    "FLAGS([sys.argv[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12306,
     "status": "ok",
     "timestamp": 1587377135025,
     "user": {
      "displayName": "Pulkit Sharma",
      "photoUrl": "",
      "userId": "18424301328354316266"
     },
     "user_tz": -330
    },
    "id": "1RFZ7-7DwOI9",
    "outputId": "44623911-a80c-44b0-b1ee-59d783555624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n",
      "classes loaded\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.tiny:\n",
    "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
    "else:\n",
    "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
    "\n",
    "# Load weights and classes\n",
    "yolo.load_weights(FLAGS.weights).expect_partial()\n",
    "print('weights loaded')\n",
    "\n",
    "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
    "print('classes loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFvo61Cqw0Hc"
   },
   "outputs": [],
   "source": [
    "video = open(\"video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4x_T9Nk_xb0"
   },
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    return warped,M\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(frame,Dict,list_of_close,list_of_connected):\n",
    "\n",
    "    \n",
    "    list_of_close =list(list_of_close)\n",
    "    for key,value  in Dict.items():\n",
    "        coord1 = value[1]\n",
    "        coord2 = value[2]\n",
    "        area = (coord1[0]-coord2[0])*(coord1[1]-coord2[1])\n",
    "        if area > 8000:\n",
    "            continue\n",
    "        if key in list_of_close:\n",
    "            frame = cv2.rectangle(frame,coord1,coord2,(0,0,255),2)\n",
    "        else:\n",
    "            frame = cv2.rectangle(frame,coord1,coord2,(255,0,0),2)\n",
    "    for connection in list_of_connected:\n",
    "        key1,key2 = connection.split(\"-\")\n",
    "        coord1 = Dict[key1][0]\n",
    "        coord2 = Dict[key2][0]\n",
    "        frame = cv2.line(frame,coord1,coord2,(0,0,255),1)\n",
    "        \n",
    "    return frame\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_distance(Dict,matrix,scale_factor=1):\n",
    "    warped_dict = {}\n",
    "    for key,value in Dict.items():\n",
    "        warped_dict[key]=return_point(matrix,value[0])\n",
    "    \n",
    "    list_of_close=set()\n",
    "    list_of_connected =set() \n",
    "    for key1,value1 in warped_dict.items():\n",
    "        for key2,value2 in warped_dict.items():\n",
    "            if key1 == key2:\n",
    "                continue\n",
    "            dist = distance.euclidean(value1,value2)*scale_factor\n",
    "            if dist < 50:\n",
    "                list_of_connected.add(key1+\"-\"+key2)\n",
    "                list_of_close.add(key1)\n",
    "                list_of_close.add(key2)\n",
    "        \n",
    "    return list_of_close,list_of_connected\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(img, outputs, class_names):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    Dict={}\n",
    "    j = 0\n",
    "    for i in range(nums):\n",
    "        \n",
    "        if class_names[int(classes[i])] == 'person':\n",
    "            x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "            x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "            (x1,y1) = x1y1\n",
    "            (x2,y2) = x2y2\n",
    "            m1 = int((x2-x1)/2)+x1\n",
    "            m2 = int((y2-y1)/2)+y1\n",
    "            coord = (m1,m2)\n",
    "            Dict[\"person\"+str(j)] = [coord,(x1,y1),(x2,y2)]\n",
    "            j+=1\n",
    "    \n",
    "    return Dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuPsRmAqB6Hr"
   },
   "outputs": [],
   "source": [
    "def return_point(matrix,p):\n",
    "    px = (matrix[0][0]*p[0] + matrix[0][1]*p[1] + matrix[0][2]) / ((matrix[2][0]*p[0] + matrix[2][1]*p[1] + matrix[2][2]))\n",
    "    py = (matrix[1][0]*p[0] + matrix[1][1]*p[1] + matrix[1][2]) / ((matrix[2][0]*p[0] + matrix[2][1]*p[1] + matrix[2][2]))\n",
    "    p_after = (int(px), int(py))\n",
    "    return p_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uQ2Jq7PX_2hv",
    "outputId": "44ed9780-6470-4c60-8088-c120de160480",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('video4.mp4')\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter(\"output.avi\",fourcc, 30,(width,height))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame1 = frame\n",
    "        width,height,channel = frame.shape\n",
    "        img = tf.expand_dims(frame, 0)\n",
    "        img = transform_images(img, FLAGS.size)\n",
    "        \n",
    "        boxes, scores, classes, nums = yolo(img)\n",
    "        \n",
    "        #cv2.circle(frame,(300,150),5,(0,0,255),-1)\n",
    "        #cv2.circle(frame,(640,150),5,(0,0,255),-1)\n",
    "        #cv2.circle(frame,(0,470),5,(0,0,255),-1)\n",
    "        #cv2.circle(frame,(830,470),5,(0,0,255),-1)\n",
    "        \n",
    "        #cv2.circle(frame,(600,300),5,(255,0,0),-1)\n",
    "        pts1 = np.float32([[300,150],[640,150],[0,470],[830,470]])\n",
    "        warped ,matrix= four_point_transform(frame,pts1)\n",
    "        \n",
    "        Dict = create_dict(frame,(boxes, scores, classes, nums),class_names)\n",
    "        \n",
    "        list_of_close,list_of_connected = derive_distance(Dict,matrix,scale_factor=0.8)\n",
    "\n",
    "        frame = plot_points(frame1,Dict,list_of_close,list_of_connected)\n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        #out.write(frame)\n",
    "        #cv2.imshow(\"wraped\",warped)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aR9MgVCHB0tJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPz5+6Yo60YVkzDagBM+DkH",
   "name": "Object Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
